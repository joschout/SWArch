\documentclass[a4paper,10pt]{article}

\usepackage[english]{babel}
\usepackage{graphicx}
\graphicspath{{./figures/}}
\usepackage[colorlinks, linkcolor=black, citecolor=black, urlcolor=black]{hyperref}
\usepackage{geometry}
\geometry{tmargin=3cm, bmargin=2.2cm, lmargin=2.2cm, rmargin=2cm}
\usepackage{todonotes} %Used for the figure placeholders

\begin{document}
\input{titlepage}

\tableofcontents
\newpage

\section{Introduction}\label{sec:introduction}

\section{Attribute-driven design documentation}\label{sec:add}
\subsection{Decomposition 1: The eDocs System (Av1, P1, UC4, UC5)}
\subsubsection{Module to decompose}
In this run we decompose the \emph{eDocs System} as a whole.

\subsubsection{Selected architectural drivers}
The selected non-functional drivers for this decomposition are:

\begin{itemize}
    \item \emph{Av1}: Document generation failure
    \item \emph{P1}: Document generation
\end{itemize}

There are two use cases about the generation of documents. These qre thus selected as the functional drivers. These use cases are:

\begin{itemize}
    \item \emph{UC4}: Generate payslip
    \item \emph{UC5}: Generate invoice
\end{itemize}

\paragraph{Rationale}
\emph{Av1} and \emph{P1} were chosen because both have a high priority. They where selected among the other high-priority quality requirements because they both concern the generation of documents, which is essential to the other requirements of the eDocs System.
UC4 and UC5 in the eDocs System rely on the generation of documents and are thus selected as functional drivers.

\subsubsection{Architectural design}
\paragraph{Scheduling for P1}
P1 specifies that the system(s) processing the raw data must be able to cope with a potentially large amount of incoming data by scheduling the different processing jobs. For this we introduce the \texttt{DocumentGenerationScheduler} that takes a coordinating role and guarantees all deadlines for all processing jobs to be met. More precisely, the \texttt{DocumentGenerationScheduler} maintains a dynamic queue to which recurring batches of document processing jobs as well as prioritized document processing jobs (critical, diamond, gold, silver, restarted) are added according to their deadline. This queue is pulled on a regular basis by one or more \texttt{DocumentGenerationProcessors} following a shortest-deadline-first approach in order to prevent documents from being processed beyond their respective deadline.

\paragraph{Dedicated persistent databases for Av1}
Besides the performance of the system processing raw data, it is also important that all types of persistent data remain available in the presence of software or hardware failures.
First, Av1 specifies that a failure of the internal infrastructure for generating documents from raw data does not affect the availability of any type of persistent data, such as (i) the personal document stores, (ii) the status of ongoing document processing jobs, (iii) billing data, etc. Therefore, the storage of persistent data is handled by dedicated databases, or more precisely, the components handling the storage of persistent data do not handle the generation of documents. For security reasons, we introduce database components for different persistent datatypes. We introduce two database components at this point, \texttt{TemplateDB} and \texttt{DocumentDB}. \texttt{TemplateDB} contains the templates for documents to be generated. The 

\paragraph{Unaffected functionality of other components}
Next to storing the  persistent data in a dedicated databases, Av1 also requires the other functionality of the system to remain unaffected when the infrastructure for document generation fails or crashes. This functionality includes (i) the personal document stores, (ii) the status overview for Customer Administrator, (iii) delivering the raw data, etc.
For  

\paragraph{Failure detection for Av3}
Third, Av3 also requires a failure of the primary database to be detected within five seconds. To tackle this, we make the ReplicationManager introduced above responsible for detecting any such failures. For this we use the read and write operations performed on the primary database as implicit ping/echo messages. This means that reading and writing data is used as a ping whereas the reply from the database, the requested data in case of reading and a confirmation in case of writing, is used as echo. To assure detection within five seconds the manager sends an explicit ping message to the primary database if no read or write operation was performed for a period of four seconds. The primary database must then reply within one second. When detecting a failure the ReplicationManager must switch to degraded modus. Furthermore, the ReplicationManager will send a notification to the sub- system responsible for forwarding notifications to the intended parties (i.e. in this case the PMS system administrator should be notified).

\paragraph{Omitting new sensor data}
Both quality scenarios include a fall back modus, respectively called overload modus (P1) and degraded modus (Av3), in case the requirements are not achieved. Both these modi allow to omit at most two (consecutive) sensor data updates for patients with a green risk level. Overload modus is determined by the SensorDataScheduler whereas degraded modus is determined by the ReplicationManager for Av3. Should both the SensorDataScheduler and the ReplicationManager separately be able to drop two updates, up to four sensor data updates could be omitted (i.e. two by the SensorDataScheduler in overload modus and two by the ReplicationManager in degraded modus), thereby violating both quality scenarios. To avoid this, the omission of sensor data updates must be determined in a single location. Therefore, we decided that the ReplicationManager informs the SensorDataScheduler when degraded modus is required (i.e. when the primary database fails). Thus it is always the responsibility of the SensorDataScheduler to determine whether a sensor data update can be omitted or not.

\paragraph{Reading vs writing sensor data}
Computing clinical models (UC15 ) requires to retrieve a patientâ€™s monitoring history (i.e. read access to the sensor data storage). As a consequence the SensorDataScheduler will contain both read and write requests in its queue. Handling the read requests can interfere with achieving the deadlines for storing sensor data as required by P1, especially if the number of read requests grows very large (i.e. when the number of monitored patients grows large). To minimize this interference, we decided to define a deadline of five minutes for read requests, i.e. longer than all write requests. In normal modus, write requests have higher priority while there is no starvation of read requests due to the deadline. In overload modus, starvation of read requests can occur just as is the case for write requests for sensor data concerning patients with a green of yellow risk level.

<<<<<<< HEAD
\paragraph{Handling race conditions} By introducing the SensorDataScheduler, read and write requests for sensor data are handled asynchronously. However, it can be the case that new sensor data is stored and shortly after requested again. For example, for now, we presume that the GatewayFacade (which first receives the new sensor data) stores this data in the sensor database and launches a new risk estimation. The new sensor data is then again fetched from the sensor database during this risk estimation.\\
=======
\paragraph{Handling race conditions} By introducing the SensorDataScheduler, read and write requests for sensor data are handled asynchronously. However, it can be the case that new sensor data is stored and shortly after requested again. For example, for now, we presume that the GatewayFacade (which first receives the new sensor data) stores this data in the sensor database and launches a new risk estimation. The new sensor data is then again fetched from the sensor database during this risk estimation.
\\
>>>>>>> origin/master

An important remark is that this flow suffers from a possible race condition where the risk estimation sub-system requests the new sensor data from the database before it is actually stored (i.e. the write operation is scheduled, but not yet executed). To remedy this race condition, the GatewayFacade includes the sensor data update in the request to schedule a risk estimation and passes the time at which it received the update to both the sensor data database and the risk estimation sub-system. As such, the latter can use the time-stamp when requesting other sensor data from the database in order to avoid receiving the new sensor data again.

\subsubsection*{Alternatives considered}
\paragraph{Alternatives for solution}
A discussion of the alternative solutions and why that were not selected.

\subsubsection{Instantiation and allocation of functionality}
\paragraph{Decomposition}
Main aspects of the resulting decomposition.

\subparagraph{ModuleB}
Per introduced component a paragraph describing its responsibilities.

\subparagraph{ModuleC}
Per introduced component a paragraph describing its responsibilities.

\begin{figure}[!htp]
    \centering
    %\includegraphics[width=0.8\textwidth]{}
    \missingfigure[figwidth=0.8\textwidth]{Component-and-connector diagram}
    \caption{Component-and-connector diagram of this decomposition.
        }\label{fig:it1-cc_main}
\end{figure}

\paragraph{Behaviour}
If needed and explanation of the behaviour of certain aspects of the design so
far.

\begin{figure}[!htp]
    \centering
    %\includegraphics[width=0.8\textwidth]{}
    \missingfigure[figwidth=0.8\textwidth]{Sequence diagram}
    \caption{Sequence diagram illustrating a key behavioural aspect.
        }\label{fig:it1-seq_aspect1}
\end{figure}

\paragraph{Deployment}
Rationale of the allocation of components to physical nodes.

\begin{figure}[!htp]
    \centering
    %\includegraphics[width=0.8\textwidth]{}
    \missingfigure[figwidth=0.8\textwidth]{Deployment diagram}
    \caption{Deployment diagram of this decomposition.
        }\label{fig:it1-depl_main}
\end{figure}

\subsubsection{Interfaces for child modules}
\subsubsection*{ModuleB}
\begin{itemize}
    \item InterfaceA
    \begin{itemize}
        \item \texttt{returnType operation1(ParamType param1)} throws TypeOfException
        \begin{itemize}
            \item Effect: Describe the effect of calling this operation.
            \item Exceptions: 
            \begin{itemize}
                \item TypeOfException: Describe when this exception is thrown.
            \end{itemize}
        \end{itemize}

        \item \texttt{returnType operation2()}
        \begin{itemize}
            \item Effect: Describe the effect of calling this operation.
            \item Exceptions: None
         \end{itemize}
    \end{itemize}
\end{itemize}

\subsubsection{Data type definitions}
Describe per complex data type used in the interfaces what it represents.

\paragraph{returnType} This data element represents X.

\paragraph{ParamType} This data element represents Y.

\subsubsection{Verify and refine}
This section describes per component which (parts of) the remaining
requirements it is responsible for.

\paragraph{ModuleB}
\begin{itemize}
    \item \emph{Z1}: name
    \item \emph{UCd}: name
\end{itemize}

\paragraph{ModuleC}
\begin{itemize}
    \item \emph{UCba}: name\\Description which part of the original use case is
        the responsibility of this component.
\end{itemize}

\subsection{Decomposition 2: Module (drivers)}
\subsubsection{Module to decompose}
\subsubsection{Selected architectural drivers}
\subsubsection{Architectural design}
\subsubsection{Instantiation and allocation of functionality}
\subsubsection{Interfaces for child modules}
\subsubsection{Data type definitions}
\subsubsection{Verify and refine}

\subsection{Decomposition 3: Module (drivers)}
\subsubsection{Module to decompose}
\subsubsection{Selected architectural drivers}
\subsubsection{Architectural design}
\subsubsection{Instantiation and allocation of functionality}
\subsubsection{Interfaces for child modules}
\subsubsection{Data type definitions}
\subsubsection{Verify and refine}

\section{Resulting partial architecture}\label{sec:architecture}
This section provides an over of the architecture constructed through ADD\@.

\subsection{Context diagram}
This subsection discusses the context diagram.

\begin{figure}[!htp]
    \centering
    %\includegraphics[width=0.8\textwidth]{}
    \missingfigure[figwidth=0.8\textwidth]{Context diagram for component-and-
        connector view.}
    \caption{Context diagram for the component-and-connector view.
        }\label{fig:cc_context}
\end{figure}

\subsection{Component-and-connector view}
A short discussion of the component-and-connector view with the key
decompositions if any.

\begin{figure}[!htp]
    \centering
    %\includegraphics[width=0.8\textwidth]{}
    \missingfigure[figwidth=0.8\textwidth]{Component-and-connector diagram}
    \caption{Primary diagram for the component-and-connector view.
        }\label{fig:cc_main}
\end{figure}

\begin{figure}[!htp]
    \centering
    %\includegraphics[width=0.8\textwidth]{}
    \missingfigure[figwidth=0.8\textwidth]{Key decomposition}
    \caption{Decomposition of a component shown in Figure~\ref{fig:cc_main}
        }\label{fig:decomp_decomp1}
\end{figure}

\subsection{Deployment view}
A short discussion of the allocation of components to physical nodes based on a
context diagram and a deployment diagram.

\begin{figure}[!htp]
    \centering
    %\includegraphics[width=0.8\textwidth]{}
    \missingfigure[figwidth=0.8\textwidth]{Context diagram for the allocation
        view.}
    \caption{Context diagram for the allocation view.}\label{fig:depl_context}
\end{figure}

\begin{figure}[!htp]
    \centering
    %\includegraphics[width=0.8\textwidth]{}
    \missingfigure[figwidth=0.8\textwidth]{Deployment diagram}
    \caption{Primary diagram for the allocation view.}\label{fig:depl_main}
\end{figure}

\end{document}
