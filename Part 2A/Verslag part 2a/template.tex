\documentclass[a4paper,10pt]{article}

\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{cite}
\graphicspath{{./figures/}}
\usepackage[colorlinks, linkcolor=black, citecolor=black, urlcolor=black]{hyperref}
\usepackage{geometry}
\geometry{tmargin=3cm, bmargin=2.2cm, lmargin=2.2cm, rmargin=2cm}
\usepackage{todonotes} %Used for the figure placeholders

\begin{document}
\input{titlepage}

\tableofcontents
\newpage

\section{Introduction}\label{sec:introduction}
In this report, we describe the execution of the attribute-driven design approach applied to the requirements of the eDocs System. Each of the following sections describes a single decomposition and each decomposition is structured according to the ADD  steps specified in \cite{SWArchinpractice}.
\section{Attribute-driven design documentation}\label{sec:add}
\subsection{Decomposition 1: The eDocs System (Av1, P1, UC4, UC5)}
\subsubsection{Module to decompose}
In this run we decompose the \emph{eDocs System} as a whole.

\subsubsection{Selected architectural drivers}
The selected non-functional drivers for this decomposition are:

\begin{itemize}
    \item \emph{Av1}: Document generation failure
    \item \emph{P1}: Document generation
\end{itemize}

There are two use cases about the generation of documents. These are thus selected as the functional drivers. These use cases are:

\begin{itemize}
    \item \emph{UC4}: Generate payslip
    \item \emph{UC5}: Generate invoice
\end{itemize}

\paragraph{Rationale}
\emph{Av1} and \emph{P1} were chosen because both have a high priority. They where selected among the other high-priority quality requirements because they both concern the generation of documents, which is essential to the other requirements of the eDocs System.
UC4 and UC5 in the eDocs System rely on the generation of documents and are thus selected as functional drivers.

\subsubsection{Architectural design}
\paragraph{Deadline scheduling for P1}
P1 specifies that the system(s) processing the raw data must be able to cope with a potentially large amount of incoming data by scheduling the different processing jobs. For this we introduce the \texttt{DocumentGenerationScheduler} that takes a coordinating role and guarantees all deadlines for all processing jobs to be met. More precisely, the \texttt{DocumentGenerationScheduler} creates new processing jobs based on the raw data received. For document processing jobs regarding recurring batches of raw data, the \texttt{DocumentGenerationScheduler} assigns a deadline to the newly created jobs based on the priority stipulated in the SLA that was negotiated with the Customer Organisation who sent the raw data (this information is retrieved from the \texttt{CustomerOrganisationDB}). For document processing jobs not part of recurring batches, the deadlines depend on the priority of the document itself, which can be retrieved from the meta data. Furthermore, the \texttt{QueueManager} maintains a dynamic queue to which the \texttt{DocumentGenerationScheduler} adds these newly created processing jobs according to their deadline. Notice that restarted documents are also put back into the queue once their generation process is restarted by the scheduler, this happens when the service offered by one or more \texttt{DocumentGenerationProcessors} is somehow disrupted. The reason for not handing this restarted job to the next \texttt{DocumentGenerationProcessor} that issues a job request is the following: the possibility exists that, between the time of labelling a failed job as restarted and handing this job to the next available \texttt{DocumentGenerationProcessor}, a new job with a stricter deadline has been added to the \texttt{QueueManager}, which causes the \texttt{DocumentGenerationProcessorManager} to give the latter job to the next available \texttt{DocumentGenerationProcessor} instead of the restarted one.

\paragraph{Parallel processing for P1}
The \texttt{QueueManager}, that we introduced earlier, is sent a pull request on a regular basis by the \texttt{DocumentGenerationProcessorManager}, which in turn provides an interface to one or more \texttt{DocumentGenerationProcessors} to request a job to be processed, following a shortest-deadline-first approach in order to prevent documents from being processed beyond their respective deadline. This \texttt{DocumentGenerationProcessorManager} oversees all processing tasks and has the ability to detect defective \texttt{DocumentGenerationProcessors}. When this \texttt{DocumentGenerationProcessorManager} detects such a defect, the document currently being generated on the respective \texttt{DocumentGenerationProcessor} will be marked as \textit{restarted} and put back into the queue that is accessed through the \texttt{QueueManager}.Notice that the processing capacity of the eDocs System can now be adjusted dynamically due to the pull methodology we just discussed.

\paragraph{Dedicated persistent databases for Av1}
Besides the performance of the system processing raw data, it is also important that all types of persistent data remain available in the presence of software or hardware failures.
First, Av1 specifies that a failure of the internal infrastructure for generating documents from raw data does not affect the availability of any type of persistent data, such as (i) the personal document stores, (ii) the status of ongoing document processing jobs, (iii) billing data, etc. Therefore, the storage of persistent data is handled by dedicated databases, or more precisely, the components handling the storage of persistent data do not handle the generation of documents. For security reasons, we introduce database components for different persistent datatypes. We introduce   a couple of database components at this point, more specifically we introduce the components \texttt{RawDataDB}, \texttt{TemplateDB}, \texttt{CustomerOrganizationDB} and \texttt{DocumentDB}. They store the raw data, the templates for documents, the information about customer organizations who are clients to eDocs end the generated documents, respectively. The \texttt{RawDataGateway} is the component that puts raw data in the \texttt{RawDataDB}. When creating a document processing job,  \texttt{DocumentGenerationScheduler} queries \texttt{RawDataDB} for raw data, looks up the template for the specific  customer organization using the \texttt{TemplateDB} and \texttt{RawDataDB} components and gives the job too the \texttt{QueueManager}.

\paragraph{Unaffected functionality of other components}
Next to storing the  persistent data in a dedicated databases, Av1 also requires the other functionality of the system to remain unaffected when the infrastructure for document generation fails or crashes. This functionality includes (i) the personal document stores, (ii) the status overview for Customer Administrator, (iii) delivering the raw data, etc.
We therefore let other components handle this functionality. The \texttt{DeliveryFunctionality} component handles the delivery of documents to the Receivers and only requires access to the \texttt{RawDataDB} and \texttt{DocumentDB} components for retrieving the documents that need to be send. The delivery of raw data to the \texttt{RawDataDB} is handled by the \textbf{RawDataGateway} component. The \texttt{QueueManager} internally replicates its queue to have higher availability of the status overview for Customer Administrators when conponents for processing fail or crash. This way, the information of which job was being processed on which processor isn't lost when these components fail.


\paragraph{Unique document generation for Av1}
Av1 also requires documents to be generated and delivered exactly once.
This requirement is accomplished by introducing a\texttt{DocumentGenerationProcessorManager} component. It oversees  \texttt{DocumentGenerationProcessors}, which can ask for jobs through the interface it presentsto them. It will be notified by a \texttt{DocumentGenerationProcessor} when the latter completes its job. Subsequently, it checks the \texttt{QueueManager} for any other \texttt{DocumentGenerationProcessors} committed to this job: if there are any, the \texttt{DocumentGenerationProcessorManager} cancels their job and assigns them a new one from the queue. Finally, it gives the finished \texttt{DocumentGenerationProcessor} permission to write its generated document into the \texttt{DocumentDB}. Notice that two \texttt{DocumentGenerationProcessors} can indeed be working on the same job: if the \texttt{DocumentGenerationProcessorManager} should lose connection with a \texttt{DocumentGenerationProcessor} working on a specific job, it will change the status of that job in the queue (which is now given the status \textit{restarted}), after which it can be requested by another \texttt{DocumentGenerationProcessor}.

\paragraph{Failure detection for A1}
A1 requires that the System autonomously detects failures or crashes. For this reason, selected \textbf{Ping/Echo} as an internal mechanism to detect failures. The \texttt{NotificationHandler} periodically pings the \texttt{DocumentGenerationScheduler}, the \texttt{QueueManager} and the \texttt{DocumentGenerationProcessorManager}. These components have five seconds to get their echo response back, as this is the time interval as specified by Av1. If one of these components fails, it detects it and notifies the eDocs Operators of this problem within one minute.\\
The \texttt{DocumentGenerationScheduler} is responsible for checking if the precessors which should be working on jobs haven't failed. When a \texttt{DocumentGenerationProcessor} pulls a job from the queue using the interface provided by the \texttt{DocumentGenerationProcessorManager}, it leaves its identifier at the manager. The manager puts the identifier as meta data for the job in the queue and uses it to \textbf{Ping/Echo} the processor. If the processor stops responding, it changes the status of the job in the queue. Thereafter, the job can be pulled by another processor. If the processor starts responding again, the \texttt{DocumentGenerationProcessorManager} cancels it job, as another processor might be working on it.\\
The Customer organization can view the status of using the \texttt{CustomerOrganizationGateway}. This component handles all interactions between the System and the Customer Organization. It offers Customer Organizations the possibility to register, to authenticate to the system and to send in raw data. It is connected to the \texttt{CustomerOrganizationDB}, which stores the necessary information about the registered Customer Organizations, their SLA's and authentication methods. To enable Customer Organizations to look up the status of document processing jobs, the \texttt{CustomerOrganizationGateway} is connected to the \texttt{QueueManager}, which stores which jobs are ready to be processed, to jobs that are being processed and their status.

\subsubsection*{Alternatives considered}
\paragraph{Alternatives for pull methodology}
An alternative to the use of a pull methodology for the processing of document generation jobs would have been the use of a push methodology. With a push methodology, the \texttt{DocumentGenerationProcessorManager} maintains a list of references to all active \texttt{DocumentGenerationProcessors} to which it can push jobs. More specifically, this manager fetches jobs from the \texttt{QueueManager} and sees to it that all active \texttt{DocumentGenerationProcessors} are handed a job to process. A major disadvantage of this methodology over the pull model is that the number of \texttt{DocumentGenerationProcessors} cannot be adjusted dynamically, which is also the reason for choosing the pull methodology over this one.

\paragraph{Alternative for the Ping/Echo}
The failure of the components monitored by the \texttt{NotificationHandler} could also be done using a \textbf{heartbeat}. But this would require both the monitored components and the \texttt{NotificationHandler} to keep track of respectively when to send and receive a heartbeat. This complicates the addition of any monitored components since they would require this extra logic.


\subsubsection{Instantiation and allocation of functionality}
\paragraph{Decomposition}
Figure \ref{fig:compandcondecomp1} shows the components resulting from the decomposition in this run. Extra attention is required concerning the \texttt{DocumentGenerationProcessor}. This component actually represents multiple instances of the same processor to provide parallel processing power when necessary.
Furthermore, we instantiated \texttt{DocumentGenerationScheduler}, \texttt{DocumentGenerationProcessorManager} and \texttt{NotificationHandler} to fully achieve the selected drivers.
The responsibilities of the resulting components are as follows:

\subparagraph{CustomerOrganisationGateway}
Responsible for communication with the Customer Organisation. This consists mainly of providing the Customer Organisation with an interface for logging into the eDocs System, sending batches of raw data and consulting the management dashboard.

\subparagraph{CustomerOrganisationDB}
Responsible for the actual storage of the Customer Organisation data, including document priorities that were negotiated in the SLA.

\subparagraph{RawDataGateway}
Responsible for receiving and verifying incoming batches of raw data.

\subparagraph{RawDataDB}
Responsible for the actual storage of the Raw Data, consisting of both meta data (i.e. document priority etc.) and document data.

\subparagraph{DocumentGenerationScheduler}
Responsible for creating all jobs from incoming Raw Data and subsequently scheduling them according to deadline in the \texttt{QueueManager}.
 
\subparagraph{TemplateDB}
Responsible for the actual storage of Templates, on which all generated Documents are based.

\subparagraph{QueueManager}
Responsible for maintaining a queue of all Document Generation Jobs that are not yet completed. Note that each of these jobs is assigned a status too.

\subparagraph{DocumentGenerationProcessorManager}
Responsible for managing all active \texttt{DocumentGenerationProcessors}. More precisely, it presents these processors with an interface for pulling Document Generation Jobs from the \texttt{QueueManager} and subsequently follows up on their Document Generation Process (i.e. granting write permission to the DocumentDB if appropriate, checking processor activity, etc.)

\subparagraph{DocumentGenerationProcessor}
Responsible for processing Document Generation Jobs assigned by the \texttt{DocumentGenerationProcessorManager}. More specifically, it is able to process only one job at a time, which consists of generating the Document that is defined by the respective Document Generation Job.

\subparagraph{NotificationHandler}
Responsible for handling Notifications that can be received either from the \texttt{DocumentGenerationScheduler}, the \texttt{DocumentGenerationProcessorManager} or one of the \texttt{DocumentGenerationProcessors}.

\subparagraph{DocumentDB}
Responsible for the actual storage of the Documents that have been fully generated.

\subparagraph{DeliveryFunctionality}
Encapsulates requirements that can be assigned to a Document Delivery component that will not be decomposed any further in this run.

\begin{figure}[!htp]
	\centering
	\includegraphics[width=0.8\textwidth]{eDocsSystem.png}
	\caption{Component-and-connector diagram of the first decomposition.}
	\label{fig:compandcondecomp1}
\end{figure}

\subsubsection{Verify and refine}
This section describes per component which (parts of) the remaining
requirements it is responsible for.

\paragraph{CustomerOrganzationGateway}
\begin{itemize}
    \item \emph{UC1a}: Log in\\ Logs a Customer Organization in.
    \item \emph{UC2a}: Log out\\ Logs a Customer Organization out.
    \item \emph{UC3a}: Initiate document processing\\ Lets a Customer Organization initiate a  batch processing job by providing an interface to which it deliver raw data. Checks if the Customer Organization is logged in. Lets the Customer organization indicate the type of document to be generated and validates whether the contract of the Customer Organization allows. generating the indicate type of document.
    \item \emph{UC20a}: Update document template\\ Lets the Customer Administrator indicate that he or she wants to update one of its document templates. Indicates the document types that the corresponding customer organization is allowed to generate, and the current templates for these types. Receives the new template from the Customer Administrator.
    \item \emph{UC21}: Consult status of all document processing jobs
\end{itemize}

\paragraph{RawDataGateway}
\begin{itemize}
	\item \emph{M2}: New type of document: bank statements
    \item \emph{UC3b}: Initiate document processing\\ Validates the received data and indicates to the Customer Organization if the raw data is received correctly and validated. Stores the validated raw data via its outgoing interface.
\end{itemize}

\paragraph{RawDataDB}
\begin{itemize}
	\item \emph{UC3c}: Initiate document processing\\ Stores the validated raw data it receives and signals for a new document processing job to begin. 
\end{itemize}
\paragraph{CustomerOrganizationDB}
\begin{itemize}
	\item \emph{UC3d}: Initiate document processing\\ Stores the contract which describes which types of documents the Customer Organization can indicate to be generated.
	\item \emph{UC18}: Register customer organization
    \item \emph{UC19}: Unregister customer oganization
    \item \emph{U20b}: Update document template\\ Stores the contract which describes which types of documents the Customer Organization is allowed to generate.
\end{itemize}
\paragraph{TemplateDB}
\begin{itemize}
		\item \emph{UC20b}: Update document template\\ Stores the templates for the document types of an Customer Organization. Provides an interface to query and update these documents.
\end{itemize}
\paragraph{DocumentGenerationScheduler}
\begin{itemize}
	\item None
\end{itemize}
\paragraph{QueueManager}
\begin{itemize}
	\item \emph{P3}: Status overview for customer administrators
	\item \emph{UC21}: Consult status of all document processing jobs
\end{itemize}
\paragraph{NotificationHandler}
\begin{itemize}
	\item \emph{UC22}: Notify customer administrator
\end{itemize}
\paragraph{DocumentGenerationProcessorManager}
\begin{itemize}
	\item None
\end{itemize}
\paragraph{DocumentGenerationProcessor}
\begin{itemize}
	\item None
\end{itemize}
\paragraph{DeliveryFunctionality}
\begin{itemize}
	\item \emph{Av2}: Personal document storage failure
	\item \emph{Av3}: Zoomit failure
	\item \emph{M2}: Multiple print \& postal services
	\item \emph{M3}: Dynamic selection of the cheapest of print \& postal services
	\item \emph{P2}: Document lookups
	\item \emph{UC1b}: Log in\\ Logs a Registered Recipient in.
    \item \emph{UC2b}: Log out\\ Logs a Registered Recipient out.
	\item \emph{UC6}: Deliver document via e-mail
 	\item \emph{UC7}: Notify of e-mail delivery failure
 	\item \emph{UC8}: Deliver document via postal mail
 	\item \emph{UC9}: Deliver invoice via Zoomit
 	\item \emph{UC10}: Confirm document delivery (Zoomit)
	\item \emph{UC11}: Deliver document via personal document store
	\item \emph{UC12}: Consult personal document store
	\item \emph{UC13}: Search documents in personal document store
	\item \emph{UC14}: Consult document  in personal document store
	\item \emph{UC15}: Register to personal document store
	\item \emph{UC16}: Unregister from personal document stores
\end{itemize}
\paragraph{DocumentDB}
\begin{itemize}
	\item None
\end{itemize}



\subsection{Decomposition 2: Delivery functionality (Av2, P2, UC11, UC12, UC13, UC14)}
\subsubsection{Module to decompose}
In this run we decompose the \texttt{DeliveryFunctionality} component that was introduced in the first decomposition. 

\subsubsection{Selected architectural drivers}
The selected non-functional drivers for this decomposition are:

\begin{itemize}
	\item \emph{Av2}: Personal document storage failure
	\item \emph{P2}: Document lookups
\end{itemize}

We decompose it with the personal document store in mind. There are four use cases related to the personal document store. These are thus selected as the functional drivers. These use cases are: 

\begin{itemize}
	\item \emph{UC11}: Deliver document via personal document store
	\item \emph{UC12}: Consult personal document store
	\item \emph{UC13}: Search documents in personal document store
	\item \emph{UC14}: Consult document in personal document store
\end{itemize}

\paragraph{Rationale} \emph{P2} and \emph{A2} where chosen because they both have high to medium priority. \emph{Av2} concerns the availability of the system that stores documents in personal document stores and \emph{P2} concerns the performance of document lookups in these stores, both central parts of the eDocs system. Also, \emph{Av2} is the last high-priority non-functional requirement.

\subsubsection{Architectural design}
\paragraph{Document reference database for Av2}
A failure or crash of the internal (sub-)system responsible for storing documents in personal document stores cannot entail the loss of any documents. This is guaranteed by the fact that personal document stores merely consist of a (set of ) \texttt{DocumentReferenceDB(s)} containing references to the documents that appear to be present in the store. Whenever a document in the store is requested through the \texttt{RequestDispatcher} (discussed below), this reference database sends the appropriate request to the \texttt{DocumentDB}, which in turn sends back the right document. The same reference database then once again acts as a middle man by passing this document to the requesting component (which is either the \texttt{UserWebInterface} or the \texttt{EmailChannel}).


\paragraph{Request dispatcher for P2}
Since it should be possible to look up documents via the personal document store or an e-mail notification in a timely fashion (even in case of a large number of parallel lookups, searches or downloads), the reference database (discussed above) should be able to handle a large number of requests at once. For this reason, the \texttt{RequestDispatcher} has been created: this component bypasses all incoming document requests to one of the available \texttt{DocumentReferenceDBs} that are actively replicated, if this database is in a consistent state. This dispatcher thus acts as a load balancer too, throttling excessive document requests if no reference database would be available at the time.

\paragraph{Active replication for P2}
As was already mentioned before, the \texttt{DocumentReferenceDB} is actively replicated. To cope with this level of consistent redundancy, a \texttt{ReplicationManager} was created. This replication manager handles all updates to the database instances and manages their global consistency. Finally, the \texttt{DocumentReferenceCache} maintains a recent history of write operations on the reference database in order to keep the database in a consistent stage after a possible failure or crash of the replication manager.

\paragraph{Unaffected functionality of other components}
Next to storing the  persistent data in a dedicated databases, Av2 also requires the other functionality of the system to remain unaffected when the infrastructure for personal document stores fails or crashes. This functionality includes (i) the state of ongoing document processing jobs, (ii) generated documents delivered through other channels, (iii) billing data, etc. It is quite straightforward to see that this failure independence is a natural consequence of the encapsulation of the personal document stores in \texttt{DocumentReferenceDBs} that merely store references to the respective documents in the \texttt{DocumentDB}.

\paragraph{Failure detection for Av2}
Because the System should be able to detect a failure or crash of the internal (sub-)system responsible for storing documents in personal document stores, failure of the core \texttt{DocumentReferenceDBs} should be detected. The replication manager and request dispatcher resolve this problem by implicitly seeing their read/write operations on the respective reference database as a ping message and its answer (the requested document) as an echo message. Although this introduces some redundancy regarding the amount of ping/echo messages, there is no significant overhead due to the fact that these messages are implicitly encoded into the read/write operations on the respective database.

\paragraph{Notification handler for Av2}
Because a failure or crash of the internal (sub-)system responsible for storing documents in personal document stores should be reported, a \texttt{NotificationHandler} was created. This handler offers an interface to notify both eDocs administrators and users (through the \texttt{UserWebInterface}) in case of a failure or crash of the internal (sub-)system.

\subsubsection*{Alternatives considered}
\paragraph{Alternatives for active replication}
An alternative to the use of active replication would have been the use of passive redundancy. With passive redundancy, only one of the replicas is able to respond to incoming requests (i.e. the primary database). As the name indicates, other replicas merely serve as dormant (i.e. passive) copies, waiting to be activated in case of a failure of the primary replica. The disadvantage of this passive methodology however, is that it is not scalable with regard to the number of incoming requests (which is exactly what \emph{Av2} requires).

\paragraph{Alternatives for ping/echo}
The failure of a database component can also be detected by relying on a heartbeat, periodically initiated by the component itself. This would require both the receiving (i.e. database component) and the requesting (i.e. replication manager and request dispatcher) end to keep track of respectively when to send and receive a heartbeat. This complicates the addition of any database components since they would require this extra logic.

\subsubsection{Instantiation and allocation of functionality}
\paragraph{Decomposition}
Figure \ref{fig:compandcondecomp2} shows the components resulting from the decomposition in this run. Extra attention is required concerning the \texttt{DocumentReferenceDB}. This component actually represents multiple actively replicated instances of the same database to provide parallel lookups, searches and downloads when necessary. Furthermore, we instantiated \texttt{ChannelDispatcher}, \texttt{ReplicationManager} and \texttt{RequestDispatcher} to fully achieve the selected drivers.
The responsibilities of the resulting components are as follows:

\subparagraph{DocumentDB}
See \texttt{DocumentDB} in decompositon 1.

\subparagraph{RawDataDB}
See \texttt{RawDataDB} in decompositon 1.

\subparagraph{NotificationHandler}
Next to the responsibilities already mentioned in decomposition 1, it is also responsible for handling Notifications that can be received from the \texttt{ReplicationManager}.

\subparagraph{CustomerOrganisationGateway}
See \texttt{CustomerOrganizationGateway} in decompositon 1.

\subparagraph{UserWebInterface}
Responsible for presenting a user friendly view of all System functionality that is externally accessible by users.

\subparagraph{ChannelDispatcher}
Responsible for dispatching documents to the appropriate channel based on their delivery information that it retrieves from the raw data database.

\subparagraph{EmailChannel}
Responsible for sending documents to recipients by email either as an attachment or as a reference link.

\subparagraph{ZoomitChannel}
Responsible for sending documents to recipients through Zoomit.

\subparagraph{PrintAndPostalServiceChannel}
Responsible for sending documents to recipients via print and postal service.

\subparagraph{PersonalDocumentStoreChannel}
Encapsulates the responsibility of providing documents to recipients through their Personal Document Store.

\subparagraph{ReplicationManager}
Responsible for managing all write operations on the actively replicated Document Reference Databases.

\subparagraph{DocumentReferenceCache}
Responsible for caching all Document References that are in the process of being written in the Document Reference Database by the Replication Manager, in case the latter should encounter any type of failure during this process.

\subparagraph{DocumentReferenceDB}
Responsible for the actual storage of the Document References that refer to Documents in the Document Database.

\subparagraph{RequestDispatcher}
Responsible for dispatching incoming Document requests to one of the available active replicas in the Document Reference Database.

\begin{figure}[!htp]
	\centering
	\includegraphics[width=0.8\textwidth]{DeliveryFunctionality.png}
	\caption{Component-and-connector diagram of the second decomposition.
	}\label{fig:compandcondecomp2}
\end{figure}

\subsubsection{Verify and refine}
This section maps the requirements not yet tackled to the components defined so far.
\paragraph{ChannelDispatcher}
\begin{itemize}
	\item None
\end{itemize}

\paragraph{EmailChannel}
\begin{itemize}
	\item \emph{UC6}: Deliver document via e-mai
	\item \emph{UC7}: Notify of e-mail delivery failure
\end{itemize}

\paragraph{ZoomitChannel}
\begin{itemize}
	\item \emph{Av3}: Zoomit failure
	\item \emph{UC9}: Deliver invoice via Zoomit
	\item \emph{UC10}: Confirm document delivery (Zoomit)
\end{itemize}

\paragraph{PrintAndPostalService}
\begin{itemize}
	\item \emph{M2}: Multiple print \& postal services
	\item \emph{M3}: Dynamic selection of the cheapest of print \& postal services
	\item \emph{UC8}: Deliver via postal mail
\end{itemize}

\paragraph{NotificationHandler}
\begin{itemize}
	\item None
\end{itemize}

\paragraph{ReplicationManager}
\begin{itemize}
	\item None
\end{itemize}

\paragraph{DocumentReferenceCache}
\begin{itemize}
	\item None
\end{itemize}

\paragraph{DocumentReferenceDB}
\begin{itemize}
	\item \emph{UC11}: Deliver document via personal document store
	\item \emph{UC13b}: Search documents in personal document store\\ Delivers requested documents
	\item \emph{UC14b}: Consult document in personal document store\\ Delivers requested documents
\end{itemize}

\paragraph{RequestDispatcher}
\begin{itemize}
	\item \emph{UC13a}: Search documents in personal document store\\ Handles incoming Document requests
	\item \emph{UC14a}: Consult document in personal document store\\ Handles incoming Document requests
\end{itemize}

\paragraph{RawDataDB}
\begin{itemize}
	\item None
\end{itemize}

\paragraph{DocumentDB}
\begin{itemize}
	\item None
\end{itemize}

\paragraph{CustomerOrganizationGateway}
\begin{itemize}
	\item None
\end{itemize}

\paragraph{UserWebInterface}
\begin{itemize}
	\item \emph{UC1b}: Log in\\ Logs a Registered Recipient in.
    \item \emph{UC2b}: Log out\\ Logs a Registered Recipient out. 
	\item \emph{UC12}: Consult personal document store
    \item \emph{UC15}: Register to personal document store
    \item \emph{UC16}: Unregister from personal document store
\end{itemize}

\subsection{Decomposition 3: RawDataGateway (M1, UC3c)}
\subsubsection{Module to decompose}
In this run we decompose the \texttt{RawDataGateway} component  introduced in the first run

\subsubsection{Selected architectural drivers}
The non-functional requirements we selected for this decomposition are:
\begin{itemize}
	\item \emph{M1}: New type of document: bank statements
\end{itemize}
There is one use case that is affected by adding a new type of document. The following use case is thus the only functional driver of this decomposition:
\begin{itemize}
	\item \emph{UC3b}: Initiate document processing\\ Validates the received data and indicates to the Customer Organization if the raw data is received correctly and validated. Stores the validated raw data via its outgoing interface.
\end{itemize}

\paragraph{Rationale} \emph{M1} is the last remaining medium priority non-functional requirement. The other high and medium priority non-functional requirements were already tackled in decompositions 1 and 2. 
\subsubsection{Architectural design}
\paragraph{Adding a new type of document to be verified} \emph{M1} requires the functionality for receiving and verifying raw data to be extendible to support new document types. We therefore introduce a \texttt{RawDataDispatcher} component. This component receives incoming raw data from the \texttt{DataReceiver} component, which acts as a buffer between the \texttt{RawDataDispatcher} and the \texttt{CustomerOrganizationGateway} components to control congestion when large amounts of raw data arrive. The \texttt{RawDataDispatcher} is connected to components that verify the raw data. There is a component for each type of document, that is, an \texttt{InvoiceVerifier}, a \texttt{PayslipVerifier} and a \texttt{BankslipVerifier}. As mentioned in \emph{UC3}, the Customer Organization indicates the type of document to be generated using the interface of the \texttt{CustomerOrganizationGateway}, which validates whether the contract of the user allows generating the indicated document type. If the contract covers the indicated document type, the \texttt{CustomerOrganizationGateway} signals the raw data dispatcher which of the verifier components it should use to verify the incoming raw data. After verification, a \texttt{Verifier} will store the raw data in the \texttt{RawDataDB}. Note that a verifier also checks if the number of entries in the batch does not exceed the maximally allowed number as agreed upon in the SLA. A verifier gets this maximum value from the \texttt{CustomerOrganizationDB}.\\

If eDocs wants to extend the functionality  of the System to other types of documents, it can create a new verifying component for the corresponding kind of raw data. It will have to update the \texttt{RawDataDispatcher}, since the \texttt{RawDataDispatcher} requires knowledge of which \texttt{Verifiers} it can send data to. Only a slight modification to the \texttt{CustomerOrganizationGateway} is needed, i.e. the possibility for the Customer Organization to choose the new document type.

\paragraph{Notifying the Customer Organization of incorrect data}
The eDocs System must indicate to the Customer Organization that the raw data is received correctly. If the System cannot validate the received data, the Customer Organization must also be notified. We therefore introduce a \texttt{NotificationHandler} component which gets input from the \texttt{InvoiceVerifier}, \texttt{PayslipVerifier} and \texttt{BankslipVerifier} components and and is responsible for notifying the \texttt{CustomerOrganizationGateway} component.

\paragraph{Other components affected by M1}
The \texttt{TemplateDB} component does not need to change to support new types of documents, since its interface for storing template is generic. The \texttt{DocumentGenerationProcessor} component also does not need to change, since it receives all the information necessary to generate a document from the job that the \texttt{DocumentGenerationScheduler} creates. The latter pulls the necessary template and raw data generically from the \texttt{TemplateDB} and the \texttt{RawDataDB}.
\subsubsection{Instantiation and allocation of functionality}
\paragraph{Decomposition}
Figure \ref{fig:compandcondecomp3} shows the component-and-connector diagram resulting from this decompostion. Notice that with respect to figure  \ref{fig:compandcondecomp1}, the \texttt{RawDataGateway} has interfaces employs additional interfaces which were not yet foreseen in the first decomposition. More specifically, the new interfaces are VerifierMgmt, DeliverNotification and DBMgmt.\\
The responsibilities of the resulting conponents are as follows:

\subparagraph{DataReceiver} Responsible for buffering the incoming raw data received from a Customer Organization.

\subparagraph{RawDataDispatcher} Responsible for sending the raw data to the component designed to verify raw data of that particular type. Has an interface used by eDocs administrators to update its knowledge of available raw data verifiers where it can send raw data to (M1).

\subparagraph{InvoiceVerifier} Responsible for verifying the raw data corresponding to invoices. This component validates the raw data. If the raw data belongs to the a recurring batch of data, the component checks if the raw data does not contain more than the maximally allowed number of documents to be generated. It gets this maximum value by querying the \texttt{CustomerOrganizationDB}. It also validates the individual entries of the raw data. Both in the cases of success and failure of the verification, it forwards a notification to the \texttt{NotificationHandler} (UC3a).

\subparagraph{PayslipVerifier} Responsible for verifying the raw data corresponding to payslips. Has the same functionality as \texttt{InvoiceVerifier}, but for payslips.

\subparagraph{BankslipVerifier} Responsible for verifying the raw data corresponding to bankslips. Has the same functionality as \texttt{InvoiceVerifier}, but for bankslips. This component is given as an example for extending the functionality to a new document type (M1).

\subparagraph{NotificationHandler} Next to the responsibilities already mentioned in decomposition 1 and 2, it is also responsible for communication with the Customer Organization about the success or failure of the verification of the received raw data.

\subparagraph{CustomerOrganizationGateway} See \texttt{CustomerOrganizationGateway} in decompositon 1.

\subparagraph{TemplateDB} See \texttt{TemplateDB} in decompositon 1.
\subparagraph{CustomerOrganizatonDB} See \texttt{CustomerOrganizatonDB} in decompositon 1.
\subparagraph{RawDataDB} See \texttt{RawDataDB} in decompositon 1.

\begin{figure}[!htp]
	\centering
	\includegraphics[width=0.8\textwidth]{RawDataGateway.png}
	\caption{Component-and-connector diagram resulting from the third decomposition.
	}\label{fig:compandcondecomp3}
\end{figure}

\subsubsection{Verify and refine}
This section maps the requirements not yet tackled to the components defined so far.

\subparagraph{DataReceiver}
\begin{itemize}
	\item \emph{UC3b1}: Initiate document processing\\ Receives the incoming Raw Data.
\end{itemize}

\subparagraph{RawDataDispatcher}
\begin{itemize}
	\item \emph{UC3b2}: Initiate document processing\\ Dispatches the incoming Raw Data to the appropriate verifier.
\end{itemize}

\subparagraph{InvoiceVerifier}
\begin{itemize}
	\item \emph{UC3b2a}: Initiate document processing\\ Verifies the received raw Invoice data and indicates to the Notification Handler if the raw data is received correctly and verified.
\end{itemize}

\subparagraph{PayslipVerifier}
\begin{itemize}
	\item \emph{UC3b2b}: Initiate document processing\\ Verifies the received raw Payslip data and indicates to the Notification Handler if the raw data is received correctly and verified.
\end{itemize}

\subparagraph{BankslipVerifier}
\begin{itemize}
	\item \emph{UC3b2c}: Initiate document processing\\ Verifies the received raw Bankslip data and indicates to the Notification Handler if the raw data is received correctly and verified.
\end{itemize}

\subparagraph{NotificationHandler}
\begin{itemize}
	\item \emph{UC3b3}: Initiate document processing\\ Indicates to the Customer Organisation if the raw data is received correctly and verified.
\end{itemize}

\subparagraph{CustomerOrganizationGateway}
\begin{itemize}
	\item None
\end{itemize}

\subparagraph{TemplateDB}
\begin{itemize}
	\item None
\end{itemize}

\subparagraph{CustomerOrganizatonDB}
\begin{itemize}
	\item None
\end{itemize}

\subparagraph{RawDataDB}
\begin{itemize}
	\item None
\end{itemize}

\section{Resulting partial architecture}\label{sec:architecture}
This section describes the architecture of the eDocs System resulting from the attribute driven design (ADD\@) process described throughout the above sections. This architecture is only partial (i.e. not complete), since the design process was not completed yet.
In this section, we show the structure of the system in terms of its components using a component-and-connector view. We do not repeat the list of components or their responsibilities, since they are identical to the ones that were already discussed in the decompositions above.

\subsection{Component-and-connector view}
Figure \ref{fig:partArch} shows the primary diagram of the component-and-connector view. For readability reasons, we chose to bundle the components related to delivering documents into the super-component DeliveryFunctionality and the components related to the transfer of raw data into the super-component RawDataGateway. Both super-components were already decomposed earlier and will therefore not be discussed any further.

\begin{figure}[!htp]
	\centering
	\includegraphics[width=0.8\textwidth]{PartialArchitecture1.png}
	\caption{Overview of the partial architecture.
	}\label{fig:partArch}
\end{figure}

\bibliography{references.bib}
\bibliographystyle{plain}
\end{document}


