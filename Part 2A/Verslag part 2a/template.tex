\documentclass[a4paper,10pt]{article}

\usepackage[english]{babel}
\usepackage{graphicx}
\graphicspath{{./figures/}}
\usepackage[colorlinks, linkcolor=black, citecolor=black, urlcolor=black]{hyperref}
\usepackage{geometry}
\geometry{tmargin=3cm, bmargin=2.2cm, lmargin=2.2cm, rmargin=2cm}
\usepackage{todonotes} %Used for the figure placeholders

\begin{document}
\input{titlepage}

\tableofcontents
\newpage

\section{Introduction}\label{sec:introduction}

\section{Attribute-driven design documentation}\label{sec:add}
\subsection{Decomposition 1: The eDocs System (Av1, P1, UC4, UC5)}
\subsubsection{Module to decompose}
In this run we decompose the \emph{eDocs System} as a whole.

\subsubsection{Selected architectural drivers}
The selected non-functional drivers for this decomposition are:

\begin{itemize}
    \item \emph{Av1}: Document generation failure
    \item \emph{P1}: Document generation
\end{itemize}

There are two use cases about the generation of documents. These qre thus selected as the functional drivers. These use cases are:

\begin{itemize}
    \item \emph{UC4}: Generate payslip
    \item \emph{UC5}: Generate invoice
\end{itemize}

\paragraph{Rationale}
\emph{Av1} and \emph{P1} were chosen because both have a high priority. They where selected among the other high-priority quality requirements because they both concern the generation of documents, which is essential to the other requirements of the eDocs System.
UC4 and UC5 in the eDocs System rely on the generation of documents and are thus selected as functional drivers.

\subsubsection{Architectural design}
\paragraph{Deadline scheduling for P1}
P1 specifies that the system(s) processing the raw data must be able to cope with a potentially large amount of incoming data by scheduling the different processing jobs. For this we introduce the \texttt{DocumentGenerationScheduler} that takes a coordinating role and guarantees all deadlines for all processing jobs to be met. More precisely, the \texttt{DocumentGenerationScheduler} creates new processing jobs based on the raw data received. For document processing jobs regarding recurring batches of raw data, the \texttt{DocumentGenerationScheduler} assigns a deadline to the newly created jobs based on the priority stipulated in the SLA that was negotiated with the Customer Organisation who sent the raw data (this information is retrieved from the \texttt{CustomerOrganisationDB}). For document processing jobs not part of recurring batches, the deadlines depend on the priority of the document itself, which can be retrieved from the meta data. Furthermore, the \texttt{QueueManager} maintains a dynamic queue to which the \texttt{DocumentGenerationScheduler} adds these newly created processing jobs according to their deadline. Notice that restarted documents are also put back into the queue once their generation process is restarted by the scheduler, this happens when the service offered by one or more \texttt{DocumentGenerationProcessors} is somehow disrupted. The reason for not handing this restarted job to the next \texttt{DocumentGenerationProcessor} that issues a job request is the following: the possibility exists that, between the time of labelling a failed job as restarted and handing this job to the next available \texttt{DocumentGenerationProcessor}, a new job with a stricter deadline has been added to the \texttt{QueueManager}, which causes the \texttt{DocumentGenerationProcessorManager} to give the latter job to the next available \texttt{DocumentGenerationProcessor} instead of the restarted one.

\paragraph{Parallel processing for P1}
The \texttt{QueueManager}, that we introduced earlier, is sent a pull request on a regular basis by the \texttt{DocumentGenerationProcessorManager}, which in turn provides an interface to one or more \texttt{DocumentGenerationProcessors} to request a job to be processed, following a shortest-deadline-first approach in order to prevent documents from being processed beyond their respective deadline. This \texttt{DocumentGenerationProcessorManager} oversees all processing tasks and has the ability to detect defective \texttt{DocumentGenerationProcessors}. When this \texttt{DocumentGenerationProcessorManager} detects such a defect, the document currently being generated on the respective \texttt{DocumentGenerationProcessor} will be marked as \textit{restarted} and put back into the queue that is accessed through the \texttt{QueueManager}.Notice that the processing capacity of the eDocs System can now be adjusted dynamically due to the pull methodology we just discussed.

\paragraph{Dedicated persistent databases for Av1}
Besides the performance of the system processing raw data, it is also important that all types of persistent data remain available in the presence of software or hardware failures.
First, Av1 specifies that a failure of the internal infrastructure for generating documents from raw data does not affect the availability of any type of persistent data, such as (i) the personal document stores, (ii) the status of ongoing document processing jobs, (iii) billing data, etc. Therefore, the storage of persistent data is handled by dedicated databases, or more precisely, the components handling the storage of persistent data do not handle the generation of documents. For security reasons, we introduce database components for different persistent datatypes. We introduce   a couple of database components at this point, more specifically we introduce the components \texttt{RawDataDB}, \texttt{TemplateDB}, \texttt{CustomerOrganizationDB} and \texttt{DocumentDB}. They store the raw data, the templates for documents, the information about customer organizations who are clients to eDocs end the generated documents, respectively. The \texttt{RawDataGateway} is the component that puts raw data in the \texttt{RawDataDB}. When creating a document processing job,  \texttt{DocumentGenerationScheduler} queries \texttt{RawDataDB} for raw data, looks up the template for the specific  customer organization using the \texttt{TemplateDB} and \texttt{RawDataDB} components and gives the job too the \texttt{QueueManager}.

\paragraph{Unaffected functionality of other components}
Next to storing the  persistent data in a dedicated databases, Av1 also requires the other functionality of the system to remain unaffected when the infrastructure for document generation fails or crashes. This functionality includes (i) the personal document stores, (ii) the status overview for Customer Administrator, (iii) delivering the raw data, etc.
We therefore let other components handle this functionality. The \texttt{DeliveryFunctionality} component handles the delivery of documents to the Receivers and only requires access to the \texttt{RawDataDB} and \texttt{DocumentDB} components for retrieving the documents that need to be send. The delivery of raw data to the \texttt{RawDataDB} is handled by the \textbf{RawDataGateway} component. The \texttt{QueueManager} internally replicates its queue to have higher availability of the status overview for Customer Administrators when conponents for processing fail or crash. This way, the information of which job was being processed on which processor isn't lost when these components fail.


\paragraph{Unique document generation for Av1}
Av1 also requires documents to be generated and delivered exactly once.
This requirement is accomplished by introducing a\texttt{DocumentGenerationProcessorManager} component. It oversees  \texttt{DocumentGenerationProcessors}, which can ask for jobs through the interface it presentsto them. It will be notified by a \texttt{DocumentGenerationProcessor} when the latter completes its job. Subsequently, it checks the \texttt{QueueManager} for any other \texttt{DocumentGenerationProcessors} committed to this job: if there are any, the \texttt{DocumentGenerationProcessorManager} cancels their job and assigns them a new one from the queue. Finally, it gives the finished \texttt{DocumentGenerationProcessor} permission to write its generated document into the \texttt{DocumentDB}. Notice that two \texttt{DocumentGenerationProcessors} can indeed be working on the same job: if the \texttt{DocumentGenerationProcessorManager} should lose connection with a \texttt{DocumentGenerationProcessor} working on a specific job, it will change the status of that job in the queue (which is now given the status \textit{restarted}), after which it can be requested by another \texttt{DocumentGenerationProcessor}.

\paragraph{Failure detection for A1}
A1 requires that the System autonomously detects failures or crashes. For this reason, selected \textbf{Ping/Echo} as an internal mechanism to detect failures. The \texttt{NotificationHandler} periodically pings the \texttt{DocumentGenerationScheduler}, the \texttt{QueueManager} and the \texttt{DocumentGenerationProcessorManager}. These components have five seconds to get their echo response back, as this is the time interval as specified by Av1. If one of these components fails, it detects it and notifies the eDocs Operators of this problem within one minute.\\
The \texttt{DocumentGenerationScheduler} is responsible for checking if the precessors which should be working on jobs haven't failed. When a \texttt{DocumentGenerationProcessor} pulls a job from the queue using the interface provided by the \texttt{DocumentGenerationProcessorManager}, it leaves its identifier at the manager. The manager puts the identifier as meta data for the job in the queue and uses it to \textbf{Ping/Echo} the processor. If the processor stops responding, it changes the status of the job in the queue. Thereafter, the job can be pulled by another processor. If the processor starts responding again, the \texttt{DocumentGenerationProcessorManager} cancels it job, as another processor might be working on it.\\
The Customer organization can view the status of using the \texttt{CustomerOrganizationGateWay}. This component handles all interactions between the System and the Customer Organization. It offers Customer Organizations the possibility to register, to authenticate to the system and to send in raw data. It is connected to the \texttt{CustomerOrganizationDB}, which stores the necessary information about the registered Customer Organizations, their SLA's and authentication methods. To enable Customer Organizations to look up the status of document processing jobs, the \texttt{CustomerOrganizationGateWay} is connected to the \texttt{QueueManager}, which stores which jobs are ready to be processed, to jobs that are being processed and their status.

\subsubsection*{Alternatives considered}
\paragraph{Alternatives for pull methodology}
An alternative to the use of a pull methodology for the processing of document generation jobs would have been the use of a push methodology. With a push methodology, the \texttt{DocumentGenerationProcessorManager} maintains a list of references to all active \texttt{DocumentGenerationProcessors} to which it can push jobs. More specifically, this manager fetches jobs from the \texttt{QueueManager} and sees to it that all active \texttt{DocumentGenerationProcessors} are handed a job to process. A major disadvantage of this methodology over the pull model is that the number of \texttt{DocumentGenerationProcessors} cannot be adjusted dynamically, which is also the reason for choosing the pull methodology over this one.

\paragraph{Alternative for the Ping/Echo}
The failure of the components monitored by the \texttt{NotificationHandler} could also be done using a \textbf{heartbeat}. But this would require both the monitored components and the \texttt{NotificationHandler} to keep track of respectively when to send and receive a heartbeat. This complicates the addition of any monitored components since they would require this extra logic.


\subsubsection{Instantiation and allocation of functionality}
\paragraph{Decomposition}
Figure 1 shows the components resulting from the decomposition in this run. Extra attention is required concerning the \texttt{DocumentGenerationProcessor}. This component actually represents multiple instances of the same processor to provide parallel processing power when necessary.
Furthermore, we instantiated \texttt{DocumentGenerationScheduler}, \texttt{DocumentGenerationProcessorManager} and \texttt{NotificationHandler} to fully achieve the selected drivers.
The responsibilities of the resulting components are as follows:

\subparagraph{CustomerOrganisationGateway}
Responsible for communication with the Customer Organisation. This consists mainly of providing the Customer Organisation with an interface for logging into the eDocs System, sending batches of raw data and consulting the management dashboard.

\subparagraph{CustomerOrganisationDB}
Responsible for the actual storage of the Customer Organisation data, including document priorities that were negotiated in the SLA.

\subparagraph{RawDataGateway}
Responsible for receiving and verifying incoming batches of raw data.

\subparagraph{RawDataDB}
Responsible for the actual storage of the Raw Data, consisting of both meta data (i.e. document priority etc.) and document data.

\subparagraph{DocumentGenerationScheduler}
Responsible for creating all jobs from incoming Raw Data and subsequently scheduling them according to deadline in the \texttt{QueueManager}.
 
\subparagraph{TemplateDB}
Responsible for the actual storage of Templates, on which all generated Documents are based.

\subparagraph{QueueManager}
Responsible for maintaining a queue of all Document Generation Jobs that are not yet completed. Note that each of these jobs is assigned a status too.

\subparagraph{DocumentGenerationProcessorManager}
Responsible for managing all active \texttt{DocumentGenerationProcessors}. More precisely, it presents these processors with an interface for pulling Document Generation Jobs from the \texttt{QueueManager} and subsequently follows up on their Document Generation Process (i.e. granting write permission to the DocumentDB if appropriate, checking processor activity, etc.)

\subparagraph{DocumentGenerationProcessor}
Responsible for processing Document Generation Jobs assigned by the \texttt{DocumentGenerationProcessorManager}. More specifically, it is able to process only one job at a time, which consists of generating the Document that is defined by the respective Document Generation Job.

\subparagraph{NotificationHandler}
Responsible for handling Notifications that can be received either from the \texttt{DocumentGenerationScheduler}, the \texttt{DocumentGenerationProcessorManager} or one of the \texttt{DocumentGenerationProcessors}.

\subparagraph{DocumentDB}
Responsible for the actual storage of the Documents that have been fully generated.

\subparagraph{DeliveryFunctionality}
Encapsulates requirements that can be assigned to a Document Delivery component that will not be decomposed any further in this run.

\begin{figure}[!htp]
    \centering
    %\includegraphics[width=0.8\textwidth]{}
    \missingfigure[figwidth=0.8\textwidth]{Component-and-connector diagram}
    \caption{Component-and-connector diagram of this decomposition.
        }\label{fig:it1-cc_main}
\end{figure}

\subsubsection{Verify and refine}
This section describes per component which (parts of) the remaining
requirements it is responsible for.

\paragraph{CustomerOrganzationGateWay}
\begin{itemize}
    \item \emph{UC1a}: Log in\\ Logs a Customer Organization in.
    \item \emph{UC2a}: Log out\\ Logs a Customer Organization out.
    \item \emph{UC3a}: Initiate document processing\\ Lets a Customer Organization initiate a  batch processing job by providing an interface to which it deliver raw data. Checks if the Customer Organization is logged in. Lets the Customer organization indicate the type of document to be generated and validates whether the contract of the Customer Organization allows. generating the indicate type of document.
    \item \emph{UC20a}: Update document template\\ Lets the Customer Administrator indicate that he or she wants to update one of its document templates. Indicates the document types that the corresponding customer organization is allowed to generate, and the current templates for these types. Receives the new template from the Customer Administrator.
    \item \emph{UC21}: Consult status of all document processing jobs
\end{itemize}

\paragraph{RawDataGateWay}
\begin{itemize}
	\item \emph{M2}: New type of document: bank statements
    \item \emph{UC3b}: Initiate document processing\\ Validates the received data and indicates to the Customer Organization if the raw data is received correctly and validated. Stores the validated raw data via its outgoing interface.
\end{itemize}

\paragraph{RawDataDB}
\begin{itemize}
	\item \emph{UC3c}: Initiate document processing\\ Stores the validated raw data it receives and signals for a new document processing job to begin. 
\end{itemize}
\paragraph{CustomerOrganizationDB}
\begin{itemize}
	\item \emph{UC3d}: Initiate document processing\\ Stores the contract which describes which types of documents the Customer Organization can indicate to be generated.
	\item \emph{UC18}: Register customer organization
    \item \emph{UC19}: Unregister customer oganization
    \item \emph{U20b}: Update document template\\ Stores the contract which describes which types of documents the Customer Organization is allowed to generate.
\end{itemize}
\paragraph{TemplateDB}
\begin{itemize}
		\item \emph{UC20b}: Update document template\\ Stores the templates for the document types of an Customer Organization. Provides an interface to query and update these documents.
\end{itemize}
\paragraph{DocumentGenerationScheduler}
\begin{itemize}
	\item None
\end{itemize}
\paragraph{QueueManager}
\begin{itemize}
	\item \emph{P3}: Status overview for customer administrators
	\item \emph{UC21}: Consult status of all document processing jobs
\end{itemize}
\paragraph{NotificationHandler}
\begin{itemize}
	\item \emph{UC22}: Notify customer administrator
\end{itemize}
\paragraph{DocumentGenerationProcessorManager}
\begin{itemize}
	\item None
\end{itemize}
\paragraph{DocumentGenerationProcessor}
\begin{itemize}
	\item None
\end{itemize}
\paragraph{DeliveryFunctionality}
\begin{itemize}
	\item \emph{Av2}:Personal document storage failure
	\item \emph{Av3}: Zoomit failure
	\item \emph{M2}: Multiple print \& postal services
	\item \emph{M3}: Dynamic selection of the cheapest of print \& postal services
	\item \emph{P2}: Document lookups
	\item \emph{UC1b}: Log in\\ Logs a Registered Recipient in.
    \item \emph{UC2b}: Log out\\ Logs a Registered Recipient out.
	\item \emph{UC6}: Deliver document via e-mail
 	\item \emph{UC7}: Notify of e-mail delivery failure
 	\item \emph{UC8}: Deliver document via postal mail
 	\item \emph{UC9}: Deliver invoice via Zoomit
 	\item \emph{UC10}: Confirm document delivery (Zoomit)
	\item \emph{UC11}: Deliver document via personal document store
	\item \emph{UC12}: Consult personal document store
	\item \emph{UC13}: Search documents in personal document store
	\item \emph{UC14}: Consult document  in personal document store
	\item \emph{UC15}: Register to personal document store
	\item \emph{UC16}: Unregister from personal document stores
\end{itemize}
\paragraph{DocumentDB}
\begin{itemize}
	\item None
\end{itemize}



\subsection{Decomposition 2: Delivery functionality (Av2, P2, UC11, UC12, UC13, UC14)}
\subsubsection{Module to decompose}
In this run we decompose the \texttt{DeliveryFunctionality} component that was introduced in the first decomposition. 

\subsubsection{Selected architectural drivers}
The selected non-functional drivers for this decomposition are:

\begin{itemize}
	\item \emph{Av2}: Personal document storage failure
	\item \emph{P2}: Document lookups
\end{itemize}

We decompose it with the personal document store in mind. There are four use cases related to the personal document store. These are thus selected as the functional drivers. These use cases are: 

\begin{itemize}
	\item \emph{UC11}: Deliver document via personal document store
	\item \emph{UC12}: Consult personal document store
	\item \emph{UC13}: Search documents in personal document store
	\item \emph{UC14}: Consult document in personal document store
\end{itemize}

\paragraph{Rationale} \emph{P2} and \emph{A2} where chosen because they both have high priority. \emph{P2} concerns the performance of document lookups and  \emph{A2} concerns the availability of the system which stores documents in personal document stores, both central parts of the eDocs system. Also, \emph{Av2} is the last high priority non-functional requirement.

\subsubsection{Architectural design}
\paragraph{Scheduling for P1}


\paragraph{Dedicated persistent databases for Av1}


\paragraph{Unaffected functionality of other components}


\paragraph{Unique document generation and delivery for Av1}


\subsubsection*{Alternatives considered}
\paragraph{Alternatives for solution}
A discussion of the alternative solutions and why that were not selected.

\subsubsection{Instantiation and allocation of functionality}
\paragraph{Decomposition}
Main aspects of the resulting decomposition.

\subparagraph{ModuleB}
Per introduced component a paragraph describing its responsibilities.

\subparagraph{ModuleC}
Per introduced component a paragraph describing its responsibilities.

\begin{figure}[!htp]
	\centering
	%\includegraphics[width=0.8\textwidth]{}
	\missingfigure[figwidth=0.8\textwidth]{Component-and-connector diagram}
	\caption{Component-and-connector diagram of this decomposition.
	}\label{fig:it1-cc_main}
\end{figure}

\subsection{Decomposition 3: Module (drivers)}
\subsubsection{Module to decompose}
\subsubsection{Selected architectural drivers}
\subsubsection{Architectural design}
\subsubsection{Instantiation and allocation of functionality}
\subsubsection{Interfaces for child modules}
\subsubsection{Data type definitions}
\subsubsection{Verify and refine}

\section{Resulting partial architecture}\label{sec:architecture}
This section provides an over of the architecture constructed through ADD\@.

\subsection{Context diagram}
This subsection discusses the context diagram.

\begin{figure}[!htp]
    \centering
    %\includegraphics[width=0.8\textwidth]{}
    \missingfigure[figwidth=0.8\textwidth]{Context diagram for component-and-
        connector view.}
    \caption{Context diagram for the component-and-connector view.
        }\label{fig:cc_context}
\end{figure}

\subsection{Component-and-connector view}
A short discussion of the component-and-connector view with the key
decompositions if any.

\begin{figure}[!htp]
    \centering
    %\includegraphics[width=0.8\textwidth]{}
    \missingfigure[figwidth=0.8\textwidth]{Component-and-connector diagram}
    \caption{Primary diagram for the component-and-connector view.
        }\label{fig:cc_main}
\end{figure}

\begin{figure}[!htp]
    \centering
    %\includegraphics[width=0.8\textwidth]{}
    \missingfigure[figwidth=0.8\textwidth]{Key decomposition}
    \caption{Decomposition of a component shown in Figure~\ref{fig:cc_main}
        }\label{fig:decomp_decomp1}
\end{figure}

\subsection{Deployment view}
A short discussion of the allocation of components to physical nodes based on a
context diagram and a deployment diagram.

\begin{figure}[!htp]
    \centering
    %\includegraphics[width=0.8\textwidth]{}
    \missingfigure[figwidth=0.8\textwidth]{Context diagram for the allocation
        view.}
    \caption{Context diagram for the allocation view.}\label{fig:depl_context}
\end{figure}

\begin{figure}[!htp]
    \centering
    %\includegraphics[width=0.8\textwidth]{}
    \missingfigure[figwidth=0.8\textwidth]{Deployment diagram}
    \caption{Primary diagram for the allocation view.}\label{fig:depl_main}
\end{figure}

\end{document}
